{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_SVM(CNN)_RU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBlq0kbL5Cxp",
        "colab_type": "text"
      },
      "source": [
        "# Инициализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yBAY_mp5Iu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown - **Монтирование GoogleDrive** \n",
        "from google.colab import drive\n",
        "drive.mount('GoogleDrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbP9p3tK5JUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #@markdown - **Размонтирование**\n",
        "# !fusermount -u GoogleDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1QelAAr5F-x",
        "colab_type": "text"
      },
      "source": [
        "# Область кодов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLvBVJOR5PQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Метод опорных векторов { display-mode: \"both\" }\n",
        "# В программе реализован метод опорных векторов с помощью градиентного спуска\n",
        "# Снижение размерности с помощью СНС\n",
        "#@markdown [Литература](https://en.wikipedia.org/wiki/Support-vector_machine)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPBFgicz8RHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown - **Настройка параметров**\n",
        "batch_size = 128 #@param {type: \"integer\"}\n",
        "num_epochs = 200 #@param {type: \"integer\"}\n",
        "C_param = 0.1 #@param {type: \"number\"}\n",
        "Reg_param = 1.0 #@param {type: \"number\"}\n",
        "delta = 1.0 #@param {type: \"number\"}\n",
        "learning_rate = 3e-3 #@param {type: \"number\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifSFXy3m9Ydk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown - **Функция ошибки и функция точности**\n",
        "def loss_fn(W,b,x_data,y_target):\n",
        "    logits = tf.subtract(tf.matmul(x_data, W),b)\n",
        "    norm_term = tf.divide(tf.reduce_sum(tf.multiply(tf.transpose(W),W)),2)\n",
        "    classification_loss = tf.reduce_mean(tf.maximum(0., tf.subtract(delta, tf.multiply(logits, y_target))))\n",
        "    total_loss = tf.add(tf.multiply(C_param,classification_loss), tf.multiply(Reg_param,norm_term))\n",
        "    return total_loss\n",
        "\n",
        "def inference_fn(W,b,x_data,y_target):\n",
        "    prediction = tf.sign(tf.subtract(tf.matmul(x_data, W), b))\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))\n",
        "    return accuracy\n",
        "# Извлечение индексов изображений 0 или 1\n",
        "def extraction_fn(data):\n",
        "    index_list = []\n",
        "    for idx in range(data.shape[0]):\n",
        "        if data[idx] == 0 or data[idx] == 1:\n",
        "            index_list.append(idx)\n",
        "    return index_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGatQsST-DQV",
        "colab_type": "code",
        "outputId": "2538a4eb-57f4-49aa-e3ad-ca7bae63c2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "#@markdown - **Извлечение обучающих и тестовых изображений**\n",
        "mnist = input_data.read_data_sets(\"sample_data/MNIST_data\", reshape=True, one_hot=False)\n",
        "data = {}\n",
        "data['train_image'] = mnist.train.images\n",
        "data['train_label'] = mnist.train.labels\n",
        "data['test_image'] = mnist.test.images\n",
        "data['test_label'] = mnist.test.labels\n",
        "\n",
        "index_list_train = extraction_fn(data['train_label'])\n",
        "index_list_test = extraction_fn(data['test_label'])\n",
        "\n",
        "data['train_image'] = mnist.train.images[index_list_train]\n",
        "data['train_label'] = mnist.train.labels[index_list_train]\n",
        "data['test_image'] = mnist.test.images[index_list_test]\n",
        "data['test_label'] = np.array(mnist.test.labels[index_list_test], dtype=np.float32)\n",
        "# data['test_label'] = mnist.test.labels[index_list_test].astype('float32')\n",
        "\n",
        "data['train_image_label'] = np.c_[data['train_image'], data['train_label']]\n",
        "num_samples, num_features = data['train_image'].shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting sample_data/MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting sample_data/MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting sample_data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting sample_data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLKXKik0Clwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown - **Снижение размерности с помощью СНС**\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    with tf.name_scope('Input'):\n",
        "        x_data = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
        "        y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
        "        x_img = tf.reshape(x_data, shape=[-1, 28, 28, 1])\n",
        "    # сети для снижения размерности\n",
        "    with tf.name_scope('Net'):\n",
        "        with tf.name_scope('Conv_1'):\n",
        "            w_1 = tf.Variable(tf.random_normal(shape=[5, 5, 1, 32]), name='w_1')\n",
        "            b_1 = tf.Variable(tf.random_normal(shape=[32]), name='b_1')\n",
        "            layer_c1 = tf.nn.relu(tf.nn.conv2d(x_img, w_1, strides=[1, 2, 2, 1], padding='VALID') + b_1)\n",
        "            layer_p1 = tf.nn.max_pool(layer_c1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "        with tf.name_scope('Conv_2'):\n",
        "            w_2 = tf.Variable(tf.random_normal(shape=[3, 3, 32, 32]), name='w_2')\n",
        "            b_2 = tf.Variable(tf.random_normal(shape=[32]), name='b_2')\n",
        "            layer_c2 = tf.nn.relu(tf.nn.conv2d(layer_p1, w_2, strides=[1, 1, 1, 1], padding='VALID') + b_2)\n",
        "            layer_p2 = tf.nn.max_pool(layer_c2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            layer_o2 = tf.layers.flatten(layer_p2)\n",
        "        num_hidden = layer_o2.get_shape().as_list()[-1]\n",
        "\n",
        "        W = tf.Variable(tf.random_normal(shape=[num_hidden, 1]), name='weights')\n",
        "        b = tf.Variable(tf.random_normal(shape=[1]), name='bias')\n",
        "    with tf.name_scope('Loss'):\n",
        "        total_loss = loss_fn(W, b, layer_o2, y_target)\n",
        "    with tf.name_scope('Accuracy'):\n",
        "        accuracy = inference_fn(W, b, layer_o2, y_target)\n",
        "    with tf.name_scope('Train'):\n",
        "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QorMHzGConr",
        "colab_type": "code",
        "outputId": "78a7f164-7180-4c44-de2a-067b56cbd5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "test_label = data['test_label'].reshape(-1, 1)\n",
        "test_label[test_label==0] = -1\n",
        "#@markdown - **Обучение сетей**\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        np.random.shuffle(data['train_image_label'])\n",
        "        image_batch = data['train_image_label'][:batch_size,:-1]\n",
        "        label_batch = data['train_image_label'][:batch_size,-1]\n",
        "        label_batch[label_batch==0] = -1\n",
        "\n",
        "        _, loss, acc = sess.run([train_op, total_loss, accuracy], feed_dict={x_data: image_batch, \n",
        "                                                                            y_target: label_batch.reshape(-1, 1)})\n",
        "        acc *= 100\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            test_loss, test_acc = sess.run([total_loss, accuracy], feed_dict={x_data: data['test_image'], \n",
        "                                                                            y_target: test_label})\n",
        "            test_acc *= 100\n",
        "            print_list = [epoch + 1, loss, acc, test_acc]\n",
        "            print('Epoch {0[0]}, loss: {0[1]:.4f}, training accuracy: {0[2]:.2f}%.'.format(print_list))\n",
        "            print(' '*10, 'Testing accuracy is {0[3]:.2f}%.'.format(print_list))\n",
        "sess.close()   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, loss: 2.1824, training accuracy: 78.91%.\n",
            "           Testing accuracy is 88.32%.\n",
            "Epoch 20, loss: 0.6349, training accuracy: 92.97%.\n",
            "           Testing accuracy is 97.16%.\n",
            "Epoch 30, loss: 0.1838, training accuracy: 98.44%.\n",
            "           Testing accuracy is 98.11%.\n",
            "Epoch 40, loss: 0.0168, training accuracy: 99.22%.\n",
            "           Testing accuracy is 99.43%.\n",
            "Epoch 50, loss: 0.1283, training accuracy: 97.66%.\n",
            "           Testing accuracy is 99.53%.\n",
            "Epoch 60, loss: 0.0825, training accuracy: 98.44%.\n",
            "           Testing accuracy is 99.53%.\n",
            "Epoch 70, loss: 0.0010, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.62%.\n",
            "Epoch 80, loss: 0.0363, training accuracy: 98.44%.\n",
            "           Testing accuracy is 99.62%.\n",
            "Epoch 90, loss: 0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.57%.\n",
            "Epoch 100, loss: 0.0003, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.62%.\n",
            "Epoch 110, loss: 0.0001, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.67%.\n",
            "Epoch 120, loss: 0.0560, training accuracy: 99.22%.\n",
            "           Testing accuracy is 99.72%.\n",
            "Epoch 130, loss: 0.1912, training accuracy: 98.44%.\n",
            "           Testing accuracy is 99.76%.\n",
            "Epoch 140, loss: 0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.81%.\n",
            "Epoch 150, loss: 0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.81%.\n",
            "Epoch 160, loss: 0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.72%.\n",
            "Epoch 170, loss: -0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.72%.\n",
            "Epoch 180, loss: 0.0001, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.81%.\n",
            "Epoch 190, loss: 0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.81%.\n",
            "Epoch 200, loss: -0.0000, training accuracy: 100.00%.\n",
            "           Testing accuracy is 99.81%.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}