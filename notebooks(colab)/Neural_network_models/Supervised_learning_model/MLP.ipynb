{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EVaqyqMSflCO","colab_type":"text"},"source":["# 初始化"]},{"cell_type":"code","metadata":{"id":"JInURxE1foyf","colab_type":"code","colab":{}},"source":["#@markdown - **挂载** \n","from google.colab import drive\n","drive.mount('GoogleDrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZFtfM6Nfq_2","colab_type":"code","colab":{}},"source":["#@markdown - **卸载**\n","!fusermount -u GoogleDrive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-YZZ5vscfsuC","colab_type":"text"},"source":["# 代码区"]},{"cell_type":"code","metadata":{"id":"PiwdJZ3vfuj2","colab_type":"code","colab":{}},"source":["#@title 多层感知机 { display-mode: \"both\" }\n","# Multilayer Perceptron\n","# 该程序实现 TensorFlow 下的三层感知机对 mnist 的分类\n","import numpy as np\n","import os, sys, ctypes\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xsrP-I8gawc","colab_type":"code","colab":{}},"source":["#@markdown - **定义打印进度条函数**\n","def print_progress(progress, epoch_num, loss, acc):\n","    \"\"\"\n","    This function draw an active progress bar.\n","    :param progress: Where we are:\n","                       type: float\n","                       value: [0,1]\n","    :param epoch_num: number of epochs for training\n","    :param loss: The loss for the specific batch in training phase.\n","\n","    :return: Progressing bar\n","    \"\"\"\n","    \n","    barLength = 30\n","\n","    assert type(progress) is float, \"id is not a float: %r\" % id\n","    assert 0 <= progress <= 1, \"variable should be between zero and one!\"\n","\n","    # 状态符号\n","    status = \"\"\n","\n","    # 打印结束后返回 \\r\\n 换行\n","    if progress >= 1:\n","        progress = 1\n","        status = \"\\r\\n\"\n","\n","    # 状态记录\n","    indicator = int(round(barLength*progress))\n","\n","    list = [str(epoch_num), \"#\"*indicator , \"-\"*(barLength-indicator), progress*100, loss, acc, status]\n","    text = \"\\rEpoch {0[0]} {0[1]} {0[2]} {0[3]:.2f}% completed loss={0[4]:.3f}, acc={0[5]:.2f}%{0[6]}\".format(list)\n","    sys.stdout.write(text)\n","    sys.stdout.flush()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNBK57kxiLFi","colab_type":"code","colab":{}},"source":["#@markdown - **设置参数**\n","events_path = 'GoogleDrive/My Drive/Colab Notebooks/Tensorboard'\n","checkpoints_path = 'GoogleDrive/My Drive/Colab Notebooks/Checkpoints'\n","max_num_checkpoints = 3\n","num_class = 10\n","batch_size = 256 #@param {type: \"integer\"}\n","num_epochs = 2000 #@param {type: \"integer\"}\n","num_neurons = 256 #@param {type: \"integer\"}\n","num_batch = 100 # 每个 epoch 中包含的 mini-batch 训练的次数，应能被 num_epochs整除\n","\n","initial_rate = 5e-3 #@param {type: \"number\"}\n","learning_rate_decay_factor = 0.95\n","decay_steps = 16.\n","k_p = 0.5 #@param {type: \"number\"}\n","\n","online_test = True #@param {type: \"boolean\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6i2U209lNBe","colab_type":"code","outputId":"4eddcc77-f503-441e-a25c-0c7de3af0891","executionInfo":{"status":"ok","timestamp":1556955940124,"user_tz":-480,"elapsed":3442,"user":{"displayName":"Лянпэн К","photoUrl":"https://lh6.googleusercontent.com/-GXVG-PbMfAw/AAAAAAAAAAI/AAAAAAAAADo/wvm2q-yqQzs/s64/photo.jpg","userId":"04289897042674768581"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["#@markdown - **训练、测试用的图像与标签的提取**\n","mnist = input_data.read_data_sets(\"sample_data/MNIST_data\", reshape=True, one_hot=True)\n","train_image = mnist.train.images\n","train_label = mnist.train.labels\n","test_image = mnist.test.images\n","test_label = mnist.test.labels\n","\n","num_samples, num_features = train_image.shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-6c3ac7854fab>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting sample_data/MNIST_data/train-images-idx3-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting sample_data/MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Extracting sample_data/MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting sample_data/MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XY_3Cy3vmkiQ","colab_type":"code","outputId":"5c207d98-1744-44ef-88e3-29f27f3563b4","executionInfo":{"status":"ok","timestamp":1556955940644,"user_tz":-480,"elapsed":3952,"user":{"displayName":"Лянпэн К","photoUrl":"https://lh6.googleusercontent.com/-GXVG-PbMfAw/AAAAAAAAAAI/AAAAAAAAADo/wvm2q-yqQzs/s64/photo.jpg","userId":"04289897042674768581"}},"colab":{"base_uri":"https://localhost:8080/","height":322}},"source":["#@markdown - **设置网络图**\n","graph = tf.Graph()\n","with graph.as_default():\n","    # learning rate 的选取策略：\n","    \n","    global_step = tf.Variable(0, name='global_step', trainable=False)\n","    decay_steps = decay_steps\n","    learning_rate = tf.train.exponential_decay(learning_rate=initial_rate,\n","                                                global_step=global_step,\n","                                                decay_steps=decay_steps,\n","                                                decay_rate=learning_rate_decay_factor,\n","                                                staircase=True,\n","                                                name='exponential_decay')\n","    \n","    # placeholder 的定义\n","    image_place = tf.placeholder(tf.float32, shape=[None, num_features], name='image')\n","    label_place = tf.placeholder(tf.float32, shape=[None, num_class], name='label')\n","    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n","\n","    # 三层感知机的网络结构\n","    #-------------------fc-1--------------------\n","    output_fc1 = tf.contrib.layers.fully_connected(inputs=image_place, num_outputs=num_neurons, scope='fc-1')\n","    #-------------------fc-2--------------------\n","    output_fc2 = tf.contrib.layers.fully_connected(inputs=output_fc1, num_outputs=num_neurons, scope='fc-2')\n","    #-----------------dropout layer-------------\n","    output_dp = tf.contrib.layers.dropout(inputs=output_fc2, keep_prob=keep_prob, scope='dropout-layer')\n","    #-------------------fc-3--------------------\n","    output_pre_softmax = tf.contrib.layers.fully_connected(inputs=output_dp, num_outputs=num_class, scope='fc-3')\n","\n","    # 定义 loss\n","    with tf.name_scope('loss'):\n","        loss_tensor = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_pre_softmax,\n","                                                                            labels=label_place, name='loss_tensor'))\n","\n","    # 定义 accuracy\n","    with tf.name_scope('accuracy'):\n","        prediction = tf.equal(tf.arg_max(output_pre_softmax, 1), tf.arg_max(label_place, 1))\n","        accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n","\n","    # 根据初值定义optimizer：(两种定义方式，第二种可以得到所有的 gradients 和 variables)\n","\n","    # with tf.name_scope('train'):\n","    #     train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_tensor, global_step=global_step)\n","\n","    with tf.name_scope('train'):\n","        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","        gradients_vars = optimizer.compute_gradients(loss_tensor)\n","        train_op = optimizer.apply_gradients(gradients_vars, global_step=global_step)\n","    \n","    # 定义 summaries\n","    tf.summary.scalar('loss', loss_tensor, collections=['train', 'test'])\n","    tf.summary.scalar('accuracy', accuracy, collections=['train', 'test'])\n","    tf.summary.scalar('global_step', global_step, collections=['train'])\n","    tf.summary.scalar('learning_rate', learning_rate, collections=['train'])\n","\n","    # 按照 'train' 和 'test' 将两种不同类型的 summaries 分别 merge\n","    summary_train = tf.summary.merge_all('train')\n","    summary_test = tf.summary.merge_all('test')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-5-d32334d25168>:32: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From <ipython-input-5-d32334d25168>:36: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.math.argmax` instead\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NxyL06rSohh9","colab_type":"code","outputId":"69ef0345-bec4-4b23-9433-95611572435d","executionInfo":{"status":"ok","timestamp":1556955973146,"user_tz":-480,"elapsed":36448,"user":{"displayName":"Лянпэн К","photoUrl":"https://lh6.googleusercontent.com/-GXVG-PbMfAw/AAAAAAAAAAI/AAAAAAAAADo/wvm2q-yqQzs/s64/photo.jpg","userId":"04289897042674768581"}},"colab":{"base_uri":"https://localhost:8080/","height":1579}},"source":["max_acc = 99.0 # 高于此精度的模型将被saved\n","min_cross = 0.1\n","with tf.Session(graph=graph) as sess:\n","    # 定义 saver，初始化以及定义 train 和 test 的 summary writer\n","    saver = tf.train.Saver(max_to_keep=max_num_checkpoints)\n","    sess.run(tf.global_variables_initializer())\n","\n","    train_summary_dir = os.path.join(events_path, 'summaries', 'train')\n","    train_summary_writer = tf.summary.FileWriter(train_summary_dir)\n","    train_summary_writer.add_graph(sess.graph)\n","\n","    test_summary_dir = os.path.join(events_path, 'summaries', 'test')\n","    test_summary_writer = tf.summary.FileWriter(test_summary_dir)\n","    test_summary_writer.add_graph(sess.graph)\n","\n","    # 随机梯度下降进行训练\n","    for num_epoch in range(num_epochs):\n","\n","        image_batch, label_batch = mnist.train.next_batch(batch_size)\n","        batch_loss, batch_acc, _, batch_summ, num_train, lr = sess.run([loss_tensor, accuracy, train_op, summary_train, global_step, learning_rate],\n","                                                                    feed_dict={image_place: image_batch, label_place: label_batch,\n","                                                                                keep_prob: k_p})\n","        batch_acc *= 100\n","        progress = float(num_epoch % num_batch + 1) / num_batch\n","        num_epoch_batch = num_epoch // num_batch + 1\n","        print_progress(progress, num_epoch_batch, batch_loss, batch_acc)\n","        # print('Epoch '+str(num_epoch+1) + ', learning rate is %.4f' % lr + ', train accuracy is '+'{:.2f}%.'.format(batch_acc))\n","        # print('Epoch '+str(num_epoch+1) + ', learning rate is %.4f' % lr + ', train loss is '+ '{:.4f}, '.format(batch_loss) + \\\n","        #         'accuracy is '+'{:.2f}%.'.format(batch_acc))\n","        train_summary_writer.add_summary(batch_summ, num_epoch)\n","\n","        checkpoints_prefix = 'model.ckpt'\n","        if (num_epoch+1) % num_batch == 0:\n","            print('Learning rate is %.4f' % lr + ', train accuracy is '+'{:.2f}%.'.format(batch_acc))\n","            if (batch_loss <= min_cross) & (batch_acc > max_acc): # 按照要求保存网络模型\n","                min_cross = batch_loss\n","                max_acc = batch_acc\n","                saver.save(sess, os.path.join(checkpoints_path, checkpoints_prefix), global_step=num_epoch+1)\n","                # print(\"\\033[0;31;40m\\tModel restored ... ...\\033[0m\\n\")\n","                print(\"Model restored ... ...\\n\")\n","                print('\\n')\n","\n","            if online_test: #定义是否实时显示测试集精度\n","                test_loss, test_acc, test_summ = sess.run([loss_tensor, accuracy, summary_test],\n","                                                            feed_dict={image_place: test_image, label_place: test_label,\n","                                                            keep_prob: 1.})\n","                test_acc *= 100\n","                print('Test accuracy is '+'{:.2f}%.\\n'.format(test_acc))\n","                test_summary_writer.add_summary(test_summ, num_epoch)\n","    \n","    # 测试集精度\n","    test_accuracy = sess.run([accuracy], feed_dict={image_place: test_image, label_place: test_label, \n","                                                    keep_prob: 1.})\n","    test_acc = test_accuracy[0]*100\n","    print(\"Final Test Accuracy is %.2f%%\" % test_acc)\n","\n","    train_summary_writer.close()\n","    test_summary_writer.close()\n","sess.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1 ##############################  100.00% completed loss=0.185, acc=93.75%\n","Learning rate is 0.0037, train accuracy is 93.75%.\n","Test accuracy is 94.59%.\n","\n","Epoch 2 ##############################  100.00% completed loss=0.094, acc=96.88%\n","Learning rate is 0.0027, train accuracy is 96.88%.\n","Test accuracy is 96.60%.\n","\n","Epoch 3 ##############################  100.00% completed loss=0.094, acc=97.66%\n","Learning rate is 0.0020, train accuracy is 97.66%.\n","Test accuracy is 96.86%.\n","\n","Epoch 4 ##############################  100.00% completed loss=0.027, acc=99.22%\n","Learning rate is 0.0015, train accuracy is 99.22%.\n","Model restored ... ...\n","\n","\n","\n","Test accuracy is 97.36%.\n","\n","Epoch 5 ##############################  100.00% completed loss=0.092, acc=96.09%\n","Learning rate is 0.0010, train accuracy is 96.09%.\n","Test accuracy is 97.66%.\n","\n","Epoch 6 ##############################  100.00% completed loss=0.040, acc=98.83%\n","Learning rate is 0.0007, train accuracy is 98.83%.\n","Test accuracy is 97.68%.\n","\n","Epoch 7 ##############################  100.00% completed loss=0.065, acc=97.66%\n","Learning rate is 0.0006, train accuracy is 97.66%.\n","Test accuracy is 97.61%.\n","\n","Epoch 8 ##############################  100.00% completed loss=0.049, acc=98.83%\n","Learning rate is 0.0004, train accuracy is 98.83%.\n","Test accuracy is 97.90%.\n","\n","Epoch 9 ##############################  100.00% completed loss=0.040, acc=98.83%\n","Learning rate is 0.0003, train accuracy is 98.83%.\n","Test accuracy is 97.95%.\n","\n","Epoch 10 ##############################  100.00% completed loss=0.045, acc=99.61%\n","Learning rate is 0.0002, train accuracy is 99.61%.\n","Test accuracy is 97.90%.\n","\n","Epoch 11 ##############################  100.00% completed loss=0.056, acc=98.44%\n","Learning rate is 0.0002, train accuracy is 98.44%.\n","Test accuracy is 97.79%.\n","\n","Epoch 12 ##############################  100.00% completed loss=0.018, acc=99.61%\n","Learning rate is 0.0001, train accuracy is 99.61%.\n","Model restored ... ...\n","\n","\n","\n","Test accuracy is 97.85%.\n","\n","Epoch 13 ##############################  100.00% completed loss=0.026, acc=98.83%\n","Learning rate is 0.0001, train accuracy is 98.83%.\n","Test accuracy is 97.89%.\n","\n","Epoch 14 ##############################  100.00% completed loss=0.044, acc=98.44%\n","Learning rate is 0.0001, train accuracy is 98.44%.\n","Test accuracy is 97.87%.\n","\n","Epoch 15 ##############################  100.00% completed loss=0.038, acc=99.22%\n","Learning rate is 0.0000, train accuracy is 99.22%.\n","Test accuracy is 97.95%.\n","\n","Epoch 16 ##############################  100.00% completed loss=0.020, acc=99.22%\n","Learning rate is 0.0000, train accuracy is 99.22%.\n","Test accuracy is 97.90%.\n","\n","Epoch 17 ##############################  100.00% completed loss=0.023, acc=99.61%\n","Learning rate is 0.0000, train accuracy is 99.61%.\n","Test accuracy is 97.91%.\n","\n","Epoch 18 ##############################  100.00% completed loss=0.007, acc=100.00%\n","Learning rate is 0.0000, train accuracy is 100.00%.\n","Model restored ... ...\n","\n","\n","\n","Test accuracy is 97.95%.\n","\n","Epoch 19 ##############################  100.00% completed loss=0.034, acc=98.83%\n","Learning rate is 0.0000, train accuracy is 98.83%.\n","Test accuracy is 97.94%.\n","\n","Epoch 20 ##############################  100.00% completed loss=0.037, acc=98.44%\n","Learning rate is 0.0000, train accuracy is 98.44%.\n","Test accuracy is 97.93%.\n","\n","Final Test Accuracy is 97.93%\n"],"name":"stdout"}]}]}